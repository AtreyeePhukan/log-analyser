# Log Analyzer and Intrusion Detection Dashboard

This project is a full-stack log analysis and anomaly detection system built using React, FastAPI, and Machine Learning. It allows users to upload log files or observe simulated log streams, analyze them for suspicious activity, and visualize security metrics through an interactive dashboard.
The system is designed for learning, experimentation, and academic demonstration rather than production deployment.

---

1. Project Overview

The application provides a web interface for analyzing security-related log data. Users upload CSV log files or view simulated logs generated by the backend. The backend processes these logs, applies a pretrained supervised machine learning model to detect anomalies, and aggregates metrics that are visualized on the frontend.

The project demonstrates:
- Full-stack integration between frontend and backend
- Log preprocessing and normalization
- ML-based anomaly detection
- Real-time data streaming using WebSockets
- Security-focused dashboard visualization

---

2. System Architecture

2.1 Frontend
- React (Vite)
- React Router for routing
- Axios for API communication
- Firebase for authentication
- Recharts for data visualization
- Tailwind CSS for styling

2.2 Backend
- FastAPI (async)
- WebSocket support for live updates
- Pretrained supervised ML model (TF-IDF + classifier)
- Rule-based log explanation layer
- PostgreSQL database hosted on Neon

2.3 Database Layer
- Database: PostgreSQL
- Hosting: Neon (serverless PostgreSQL)
- Accessed using async database operations
- Stores:
  - Parsed log entries
  - Anomaly detection results
  - Aggregated dashboard metrics
  - Suspicious IP records

Neon is used to provide a lightweight, cloud-hosted PostgreSQL database suitable for development and experimentation.

---
3.  Machine Learning Component

- The system uses a pretrained supervised machine learning model for anomaly detection.
- Logs are vectorized using TF-IDF feature extraction.
- A linear classifier (Logistic Regression–based) is used to classify log entries as normal or suspicious.
- The model is trained offline and loaded at backend startup for inference.
- Predictions are combined with heuristic and rule-based logic to improve robustness and interpretability.

---

4. Input Requirements

The application requires a CSV file containing log data to initiate analysis.

A sample CSV file is provided in the repository for testing purposes:
-sample_windows_logs.csv


5. How to Try the Application
- Open the deployed frontend application.
- Click the upload button on the home page.
- Upload `sample_windows_logs.csv`.
- View dashboards, alerts, and log tables generated from the analysis.

The system is intentionally designed to work on user-provided logs to reflect real-world security workflows.

---

6. Backend API Overview

6.1 Key Endpoints
- `POST /upload/`  
  Uploads and analyzes CSV log files.

- `GET /charts/line`  
  Returns time-series data for dashboards.

- `GET /charts/bar`  
  Returns categorical summary data.

- `GET /charts/donut`  
  Returns distribution metrics.

- `GET /metrics/`  
  Returns latest aggregated system metrics.

- `POST /explain`  
  Generates a rule-based explanation for a log message.

6.2 WebSocket Endpoints
- `/ws/logs` – Streams simulated log events in real time.
- `/ws/dashboard` – Streams live dashboard metrics.
- `/ws/insights` – Streams generated security insights.

---

6.3 Real-Time Log Simulation

To demonstrate real-time monitoring behavior, the backend simulates Windows-style and firewall-style logs. These logs are streamed using WebSockets, processed using sliding time-window logic, and evaluated for suspicious activity using both ML inference and heuristic rules.

---

7. Known Limitations

- Real-time logs are simulated rather than collected from live systems.
- The ML model is trained offline and does not update dynamically.
- One dashboard route depends on backend availability and WebSocket initialization; in free-tier deployments, backend inactivity can cause this route to fail without retry handling.
- The project is not optimized for high-throughput production environments.

---

8. Future Improvements

- Improved frontend error handling and retry logic
- Real log ingestion from external systems
- Model retraining and incremental learning
- Enhanced explainability using model interpretation techniques
- Production-ready deployment with persistent backend availability

---

9. How to Run Locally

9.1 Frontend
```bash
cd frontend
npm install
npm run dev
```
9.2 Backend
```bash
pip install -r requirements.txt
uvicorn main:app --reload
```

---
## Author
Atreyee Phukan



